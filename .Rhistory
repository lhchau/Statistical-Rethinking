mutate(fit = map2(model, formula, fit_lm))
tibble(model = str_c("b6.", 1:6),
formula = c("brain ~ mass",
"brain ~ mass + I(mass^2)",
"brain ~ mass + I(mass^2) + I(mass^3)",
"brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4)",
"brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(mass^5)",
"brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(mass^5) + I(mass^6)")) %>%
mutate(fit = map2(model, formula, fit_lm)) %>%
mutate(tidy = map(fit, tidy),
glance = map(fit, glance))
fits <- tibble(model = str_c("b6.", 1:6),
formula = c("brain ~ mass",
"brain ~ mass + I(mass^2)",
"brain ~ mass + I(mass^2) + I(mass^3)",
"brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4)",
"brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(mass^5)",
"brain ~ mass + I(mass^2) + I(mass^3) + I(mass^4) + I(mass^5) + I(mass^6)")) %>%
mutate(fit = map2(model, formula, fit_lm)) %>%
mutate(tidy = map(fit, tidy),
glance = map(fit, glance))
fits %>%
mutate(r2 = glance %>% map_dbl("r.squared"))
fits %>%
mutate(r2 = glance %>% map_dbl("r.squared")) %>%
mutate(r2_text = round(r2, digits = 2) %>% as.character() %>% str_replace(., "0.", "."))
fits <- fits %>%
mutate(r2 = glance %>% map_dbl("r.squared")) %>%
mutate(r2_text = round(r2, digits = 2) %>% as.character() %>% str_replace(., "0.", "."))
fits %>%
ggplot(aes(x = r2, y = formula, label = r2_text)) +
geom_text(color = carto_pal(7, "BurgYl")[7], size = 3.5)
fits %>%
ggplot(aes(x = r2, y = formula, label = r2_text)) +
geom_text(color = carto_pal(7, "BurgYl")[7], size = 3.5) +
scale_x_continuous(expression(italic(R)^2), limits = 0:1, breaks = 0.1) +
ylab(NULL) +
theme_classic()
fits %>%
ggplot(aes(x = r2, y = formula, label = r2_text)) +
geom_text(color = carto_pal(7, "BurgYl")[7], size = 3.5) +
scale_x_continuous(expression(italic(R)^2), limits = 0:1, breaks = 0.1) +
ylab(NULL) +
theme_classic() +
theme(text = element_text(family = "Courier"),
axis.text.y = element_text(hjust = 0),
axis.ticks.y = element_blank(),
panel.background = element_rect(fill = alpha(carto_pal(7, "BurgYl")[3], 1/4)))
fits %>%
unnest(tidy)
fits %>%
unnest(tidy) %>%
select(model, term:estimate) %>%
mutate_if(is.double, round, digits = 1) %>%
complete(model, term)
fits %>%
unnest(tidy) %>%
select(model, term:estimate) %>%
mutate_if(is.double, round, digits = 1)
fits %>%
unnest(tidy) %>%
select(model, term:estimate) %>%
mutate_if(is.double, round, digits = 1) %>%
complete(model, term) %>%
spread(key = term, value = estimate) %>%
select(model, `(Intercept)`, mass, everything())
p <-
d %>%
ggplot(aes(x = mass, y = brain)) +
geom_point(color = carto_pal(7, "BurgYl")[7]) +
scale_x_continuous("body mass (kg)", limits = c(33, 62), expand = c(0, 0)) +
ylab("brain volume (cc)") +
coord_cartesian(ylim = c(300, 1500)) +
theme_classic() +
theme(text = element_text(family = "Courier"),
panel.background = element_rect(fill = alpha(carto_pal(7, "BurgYl")[3], 1/4)))
# linear
p1 <-
p +
stat_smooth(method = "lm", fullrange = TRUE, level = .89,  # note our rare use of 89% intervals
color = carto_pal(7, "BurgYl")[6], fill = carto_pal(7, "BurgYl")[6],
size = 1/2, alpha = 1/3,
formula = y ~ x) +
ggtitle(NULL, subtitle = expression(italic(R)^2==".49"))
# quadratic
p2 <-
p +
stat_smooth(method = "lm", fullrange = TRUE, level = .89,
color = carto_pal(7, "BurgYl")[6], fill = carto_pal(7, "BurgYl")[6],
size = 1/2, alpha = 1/3,
formula = y ~ poly(x, 2)) +
ggtitle(NULL, subtitle = expression(italic(R)^2==".54"))
# cubic
p3 <-
p +
stat_smooth(method = "lm", fullrange = TRUE, level = .89,
color = carto_pal(7, "BurgYl")[6], fill = carto_pal(7, "BurgYl")[6],
size = 1/2, alpha = 1/3,
formula = y ~ poly(x, 3)) +
ggtitle(NULL, subtitle = expression(italic(R)^2==".68"))
# fourth-order polynomial
p4 <-
p +
stat_smooth(method = "lm", fullrange = TRUE, level = .89,
color = carto_pal(7, "BurgYl")[6], fill = carto_pal(7, "BurgYl")[6],
size = 1/2, alpha = 1/3,
formula = y ~ poly(x, 4)) +
ggtitle(NULL, subtitle = expression(italic(R)^2==".81"))
# fifth-order polynomial
p5 <-
p +
stat_smooth(method = "lm", fullrange = TRUE, level = .89,
color = carto_pal(7, "BurgYl")[6], fill = carto_pal(7, "BurgYl")[6],
size = 1/2, alpha = 1/3,
formula = y ~ poly(x, 5)) +
# we're adjusting the y-axis range for this plot (and the next)
coord_cartesian(ylim = c(150, 1900)) +
ggtitle(NULL, subtitle = expression(italic(R)^2==".99"))
# sixth-order polynomial
p6 <-
p +
# mark off 0 on the y-axis
geom_hline(yintercept = 0, color = carto_pal(7, "BurgYl")[2], linetype = 2) +
stat_smooth(method = "lm", fullrange = TRUE, level = .89,
color = carto_pal(7, "BurgYl")[6], fill = carto_pal(7, "BurgYl")[6],
size = 1/2, alpha = 1/3,
formula = y ~ poly(x, 6)) +
coord_cartesian(ylim = c(-300, 1500)) +
ggtitle(NULL, subtitle = expression(italic(R)^2==1))
library(patchwork)
(p1 + p2) / (p3 + p4) / (p5 + p6)
p_logp <- function(p){
if(p == 0) return(0)
p * log(p)
}
calc_entropy <- function(x){
avg_logprob <- sum(map_dbl(x, p_logp))
-1 * avg_logprob
}
calc_entropy(0.7)
library(tidyverse)
calc_entropy(0.7)
0.7*log(0.7)+0.3*log(0.3)
0.7*log2(0.7)+0.3*log2(0.3)
0.7*log(0.7)
probs <- c(0.7, 0.3)
calc_entropy(probs)
probs <- c(0.2, 0.25, 0.25, 0.3)
calc_entropy(probs)
probs <- c(1/3, 1/3, 1/3, 0)
calc_entropy(probs)
elpd <- function(object, method="LOO"){
object$output[-1] <- paste(object$output$outFilePath,object$output[-1],sep="")
if(is.null(object$output$CPO))
stop("Please specify the argument 'output_CPO = TRUE' in BayesSUR()!")
if(toupper(method) == "LOO"){
elpd <- sum(log(read.table(object$output$CPO)))
names(elpd) <- "elpd.loo"
}else if(toupper(method) == "WAIC"){
elpd <- sum(read.table(object$output$WAIC))
names(elpd) <- "elpd.waic"
}else{
stop("Please give the correct method name!")
}
return(elpd)
}
library(tidyverse)
library(rethinking)
library(tidybayes)
library(brms)
data(Laffer)
df <- Laffer
Laffer
df %>%
as_tibble() %>%
ggplot(aes(x = tax_rate, y = tax_revenue)) +
geom_point()
df <- df %>%
mutate(across(everything(), standardize),
tax_rate2 = tax_rate^2)
df
laf_line <- brm(tax_revenue ~ 1 + tax_rate,
data = df, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(exponential(1), class = sigma)),
iter = 1000, warmup = 500, chains = 4, cores = 4, seed = 123,
file = here::here("fits", "chp7", "b7h1-line.rds"))
laf_quad <- brm(tax_revenue ~ 1 + tax_rate + tax_rate2,
data = df, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(exponential(1), class = sigma)),
iter = 1000, warmup = 5000, chains = 4, cores = 4, seed = 123,
file = here::here("fits", "chp7", "b7h2-line.rds"))
laf_quad <- brm(tax_revenue ~ 1 + tax_rate + tax_rate2,
data = df, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(exponential(1), class = sigma)),
iter = 1000, warmup = 500, chains = 4, cores = 4, seed = 123,
file = here::here("fits", "chp7", "b7h2-line.rds"))
laf_quad <- brm(tax_revenue ~ 1 + tax_rate + tax_rate2,
data = df, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(exponential(1), class = sigma)),
iter = 1000, warmup = 500, chains = 4, cores = 4, seed = 123,
file = here::here("fits", "chp7", "b7h1-quad.rds"))
# spine
laf_spln <- brm(tax_revenue ~ 1 + s(tax_rate, bs = "bs"),
data = df, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(normal(0, 0.5), class = sds),
prior(exponential(1), class = sigma)),
iter = 1000, warmup = 500, chains = 4, cores = 4, seed = 123,
control = list(adapt_delta = 0.95),
file = here::here("fits", "chp7", "b7h1-spln.rds"))
tr_seq <- tibble(tax_rate = seq(0, 40, length.out = 100)) %>%
mutate(tax_rate = (tax_rate - mean(Laffer$tax_rate)) / sd(Laffer$tax_rate),
tax_rate2 = tax_rate^2)
predicted_draws(laf_line, newdata = tr_seq) %>%
median_qi(.width = 0.89) %>%
mutate(type = "Linear")
predictions <- bind_rows(
predicted_draws(laf_line, newdata = tr_seq) %>%
median_qi(.width = 0.89) %>%
mutate(type = "Linear"),
predicted_draws(laf_quad, newdata = tr_seq) %>%
median_qi(.width = 0.89) %>%
mutate(type = "Quadratic"),
predicted_draws(laf_spln, newdata = tr_seq) %>%
median_qi(.width = 0.89) %>%
mutate(type = "Spline")
)
fits <- bind_rows(
epred_draws(laf_line, newdata = tr_seq) %>%
median_qi(.width = c(0.67, 0.89, 0.97)) %>%
mutate(type = "Linear"),
epred_draws(laf_quad, newdata = tr_seq) %>%
median_qi(.width = c(0.67, 0.89, 0.97)) %>%
mutate(type = "Quadratic"),
epred_draws(laf_spln, newdata = tr_seq) %>%
median_qi(.width = c(0.67, 0.89, 0.97)) %>%
mutate(type = "Spline")
)
library(wjake)
remotes::install_github("wjakethompson/wjake")
library(wjakethompson/wjake)
library(wjakethompson)
library(wjake)
G <- sample(1:2, size = N, replace = TRUE)
N <- 1000
G <- sample(1:2, size = N, replace = TRUE)
library(rethinking)
# gender 1 tends to apply to  department 1 to department 2
D <- rbern(N, ifelse(G == 1, 0.3, 0.8)) + 1
D
count(D)
table(D)
# matrix of acceptance rates [dept, gender]
accept_rate <- matrix(c(0.1, 0.3, 0.1, 0.3), nrow = 2)
# simulate acceptance
A <- rbern(N, accept_rate[D, G])
A
df <- tibble(Gender = G,
Department = D,
Acceptance = A)
library(tidyverse)
df <- tibble(Gender = G,
Department = D,
Acceptance = A)
df <- tibble(Gender = G,
Department = D,
Acceptance = A)
df
A
accept_rate
df <- tibble(G = G,
D = D,
A = A)
library(brms)
total_G <- brm(A ~ 1 + G,
data = df, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.4), class = b),
prior(exponential(1), class = sigma)),
iter = 1000, warmup = 500, chains = 4, cores = 4, seed = 123)
direct_G <- brm(A ~ 1 + G + D,
data = df, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.4), class = b),
prior(exponential(1), class = sigma)),
iter = 1000, warmup = 500, chains = 4, cores = 4, seed = 123)
precis(total_G)
summary(total_G)
summary(direct_G)
table(G, A)
prop.table(G, A)
prop.table(table(G, A))
table(G, A)
0.411+0.086
0.382+0.121
411+86
86/497
382+121
121/503
N <- 1000
G <- sample(1:2, size = N, replace = TRUE)
# gender 1 tends to apply to  department 1 to department 2
D <- rbern(N, ifelse(G == 1, 0.3, 0.7)) + 1
# matrix of acceptance rates [dept, gender]
accept_rate <- matrix(c(0.1, 0.3, 0.1, 0.3), nrow = 2)
# simulate acceptance
A <- rbern(N, accept_rate[D, G])
table(G, A)
71/(421+71)
125/(125+383)
G <- sample(1:2, size = N, replace = TRUE)
# gender 1 tends to apply to  department 1 to department 2
D <- rbern(N, ifelse(G == 1, 0.3, 0.9)) + 1
# matrix of acceptance rates [dept, gender]
accept_rate <- matrix(c(0.1, 0.3, 0.1, 0.3), nrow = 2)
# simulate acceptance
A <- rbern(N, accept_rate[D, G])
table(G, A)
# gender 1 tends to apply to  department 1 to department 2
D <- rbern(N, ifelse(G == 1, 0.3, 0.8)) + 1
# matrix of acceptance rates [dept, gender]
accept_rate <- matrix(c(0.1, 0.3, 0.1, 0.3), nrow = 2)
# simulate acceptance
A <- rbern(N, accept_rate[D, G])
df <- tibble(G = G,
D = D,
A = A)
table(G, A)
df <- tibble(G = G,
D = D,
A = A)
a <- rnorm(1e4, 0, 10)
b <- rnorm(1e4, 0, 10)
xseq <- seq(from = -3, to = 3, len = 100)
p <- sapply(xseq, function(x) inv_logit(a+b*x))
p
plot(NULL, xlim = c(-2.5, 2.5), ylim = c(0, 1),
xlab = "x value", ylab = "probability")
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 2)
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 3)
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 1:10)
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 3)
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 2)
a <- rnorm(1e4, 0, 1.5)
b <- rnorm(1e4, 0, 1.5)
xseq <- seq(from = -3, to = 3, len = 100)
p <- sapply(xseq, function(x) inv_logit(a+b*x))
plot(NULL, xlim = c(-2.5, 2.5), ylim = c(0, 1),
xlab = "x value", ylab = "probability")
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 2)
a <- rnorm(1e4, 0, 1)
b <- rnorm(1e4, 0, 1)
xseq <- seq(from = -3, to = 3, len = 100)
p <- sapply(xseq, function(x) inv_logit(a+b*x))
plot(NULL, xlim = c(-2.5, 2.5), ylim = c(0, 1),
xlab = "x value", ylab = "probability")
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 2)
a <- rnorm(1e4, 0, 0.2)
b <- rnorm(1e4, 0, 0.5)
xseq <- seq(from = -3, to = 3, len = 100)
p <- sapply(xseq, function(x) inv_logit(a+b*x))
plot(NULL, xlim = c(-2.5, 2.5), ylim = c(0, 1),
xlab = "x value", ylab = "probability")
for(i in 1:10) lines(xseq, p[i, ], lwd = 3, col = 2)
glm_total_G <- brm(A ~ 1 + G,
data = df, family = bernoulli(link = "logit"),
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.4), class = b),
prior(exponential(1), class = sigma)),
iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 123)
glm_total_G <- brm(
A ~ 1 + G,
data = df,
family = bernoulli(link = "logit"),
iter = 2000,
warmup = 500,
chains = 4,
cores = 4,
inits = "0",
seed = 123
)
summary(glm_total_G)
glm_direct_G <- brm(
A ~ 1 + G + D,
data = df,
family = bernoulli(link = "logit"),
iter = 2000,
warmup = 500,
chains = 4,
cores = 4,
inits = "0",
seed = 123
)
summary(glm_direct_G)
##########################################################
N <- 1000
G <- sample(1:2, size = N, replace = TRUE)
# gender 1 tends to apply to  department 1 to department 2
D <- rbern(N, ifelse(G == 1, 0.3, 0.8)) + 1
# matrix of acceptance rates [dept, gender]
accept_rate <- matrix(c(0.05, 0.2, 0.1, 0.3), nrow = 2)
# simulate acceptance
A <- rbern(N, accept_rate[D, G])
table(G, A)
glm_total_G <- brm(
A ~ 1 + G,
data = df,
family = bernoulli(link = "logit"),
iter = 2000,
warmup = 500,
chains = 4,
cores = 4,
inits = "0",
seed = 123
)
glm_direct_G <- brm(
A ~ 1 + G + D,
data = df,
family = bernoulli(link = "logit"),
iter = 2000,
warmup = 500,
chains = 4,
cores = 4,
inits = "0",
seed = 123
)
summary(glm_total_G)
summary(glm_direct_G)
dat_sim <- list(A = A, D = D, G = G)
m1 <- ulam(
alist(
A ~ bernoulli(p),
logit(p) <- a[G],
a[G] ~ normal(0, 1)
), data = dat_sim, chains = 4, cores = 4
)
m2 <- ulam(
alist(
A ~ bernoulli(p),
logit(p) <- a[G, D],
matrix[G, D]:a ~ normal(0, 1)
), data = dat_sim, chains = 4, cores = 4
)
summary(m1)
summary(m2)
data("UCBadmit")
d <- UCBadmit
dat <- list(
A = d$admit,
N = d$applications,
G = ifelse(d$applicant.gender=="female", 1, 2),
D = as.integer(d$dept)
)
# total effect gender
mG <- ulam(
alist(
A ~ binomial(N, p),
logit(p) <- a[G],
a[G] ~ normal(0, 1)
), data = dat, chains = 4, cores = 4
)
# direct effects
mGD <- ulam(
alist(
A ~ binomial(N, p),
logit(p) <- a[G, D],
matrix[G, D]:a ~ normal(0, 1)
), data = dat, chains = 4, cores = 4
)
post1 <- extract.samples(mG)
PrA_G1 <- inv_logit(post1$a[, 1])
prA_G2 <- inv_logit(post1$a[, 2])
diff_prob <- PrA_G1 - prA_G2
dens(diff_prob, lwd = 4, col = 2, xlab = "Gender contrast (probability)")
# Direct effects
post2 <- extract.samples(mGD)
PrA <- inv_logit(post2$a)
diff_prob_D_ <- sapply(1:6, function(i) PrA[,1,i] - PrA[,2,i])
plot(NULL, xlim = c(-0.2, 0.3), ylim = c(0, 25),
xlab = "Gender constrast(probability)", ylab = "Density")
for(i in 1:6) dens(diff_prob_D_[, i], lwd = 4, col = 1+i, add = TRUE)
library(tidyverse)
library(rethinking)
library(tidybayes)
library(brms)
ls(pat="^V")
pat = "VanTian"
ls(pat="^V")
x <- as.Date("2018-01-01")
month(x)
months(x)
x <- c(12L, 6L, 10L)
median(x)
x
x[1, 2 ]
x[-2]
mtrx <- matrix(1:6, 3, 2)
mtrx[, -1]
mtrx
a <- c(3, 0, TRUE)
b <- c(4, 0, FALSE)
c <- (a|b)
c
