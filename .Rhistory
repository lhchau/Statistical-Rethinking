mu     <- bX*X + a[S] + bA*A,
bX     ~  dnorm(0, 0.5),
a[S]   ~  dnorm(0, 1),
bA     ~  dnorm(0, 0.5),
sigma  ~  dexp(1)
), data = df
)
m6.13 <- quap(
alist(
Y      ~  dnorm(mu, sigma),
mu     <- bX*X + a[S] + bA*A,
bX     ~  dnorm(0, 0.5),
a[S]   ~  dnorm(0, 1),
bA     ~  dnorm(0, 0.5),
sigma  ~  dexp(1)
), data = df
)
df$S <- df$S + 1
m6.13 <- quap(
alist(
Y      ~  dnorm(mu, sigma),
mu     <- bX*X + a[S] + bA*A,
bX     ~  dnorm(0, 0.5),
a[S]   ~  dnorm(0, 1),
bA     ~  dnorm(0, 0.5),
sigma  ~  dexp(1)
), data = df
)
precis(m6.13)
precis(m6.13, depth = 2)
library(tidyverse)
theme_set(theme_light())
df <- read_csv("healthcare-dataset-stroke-data.csv")
str(df)
glimmer(df)
glimpse(df)
library(tidybayes)
library(rethinking)
names(df)
View(df)
head(df)
head(df)
df <- read_csv("healthcare-dataset-stroke-data.csv") %>%
select(-id)
df
library(tidyverse)
library(rethinking)
library(brms)
library(tidybayes)
theme_set(theme_light())
lm_YX <- lm(Y ~ X, data = df)
summary(lm_YX)
df <- read_csv("healthcare-dataset-stroke-data.csv") %>%
select(A = age, S = smoking_status, Y = stroke, X = heart_disease)
lm_YX <- lm(Y ~ X, data = df)
summary(lm_YX)
df <- df %>%
mutate(S = case_when(
S == "never smoked"    ~ 0,
S == "smokes"          ~ 1,
S == "formerly smoked" ~ 2,
S == "Unknown"         ~ 3,
))
lm_YXSA <- lm(Y ~ X + S + A, data = df)
summary(lm_YXSA)
df <- read_csv("healthcare-dataset-stroke-data.csv") %>%
select(A = age, S = smoking_status, Y = stroke, X = heart_disease)
lm_YX <- lm(Y ~ X, data = df)
summary(lm_YX)
lm_YXSA <- lm(Y ~ X + S + A, data = df)
summary(lm_YXSA)
df <- df %>%
mutate(S = case_when(
S == "never smoked"    ~ 0,
S == "smokes"          ~ 1,
S == "formerly smoked" ~ 2,
S == "Unknown"         ~ 3,
))
df$S <- df$S + 1
m6.13 <- quap(
alist(
Y      ~  dnorm(mu, sigma),
mu     <- bX*X + a[S] + bA*A,
bX     ~  dnorm(0, 0.5),
a[S]   ~  dnorm(0, 1),
bA     ~  dnorm(0, 0.5),
sigma  ~  dexp(1)
), data = df
)
precis(m6.13, depth = 2)
df
sum(is.na(df$A))
sum(!is.na(df$A))
apply(df, sum(is.na()))
apply(df, sum(is.na(.)))
df$A <- standardize(df$A)
m6.13 <- quap(
alist(
Y      ~  dnorm(mu, sigma),
mu     <- bX*X + a[S] + bA*A,
bX     ~  dnorm(0, 0.5),
a[S]   ~  dnorm(0, 1),
bA     ~  dnorm(0, 0.5),
sigma  ~  dexp(1)
), data = df
)
precis(m6.13, depth = 2)
lm_YX <- lm(Y ~ X, data = df)
summary(lm_YX)
lm_YXSA <- lm(Y ~ X + S + A, data = df)
summary(lm_YXSA)
df <- read_csv("healthcare-dataset-stroke-data.csv") %>%
select(A = age, S = smoking_status, Y = stroke, X = heart_disease)
lm_YX <- lm(Y ~ X, data = df)
summary(lm_YX)
lm_YXSA <- lm(Y ~ X + S + A, data = df)
summary(lm_YXSA)
# load libraries
library(tidyverse) # metapackage of all tidyverse packages
library(naniar) # handling missing data
library(skimr) # quick overview over the dataset
library(caret) # ML toolkit
library(MLmetrics) # F1 Score
library(imbalance) # algorithms to deal with imbalanced datasets
library(gridExtra) # display plots in grids
library(patchwork) # arrange plots side by side
library(imbalance) # algorithms to deal with imbalanced datasets
install.packages('smotefamily')
library(imbalance) # algorithms to deal with imbalanced datasets
# set a seed for reproducible results
set.seed(88)
# custom plot size function
fig <- function(width, heigth){
options(repr.plot.width = width, repr.plot.height = heigth)
}
## ggplot custom theme
theme_bigfont <- theme(plot.title = element_text(size=22),
axis.text.x= element_text(size=15),
axis.text.y= element_text(size=15),
axis.title=element_text(size=18),
legend.text = element_text(size = 14))
df <- read_csv("healthcare-dataset-stroke-data.csv")
stroke_data <- read_csv("healthcare-dataset-stroke-data.csv")
# check the first few rows
head(stroke_data)
# summary of the data
summary(stroke_data)
# check unique values of categorical values
cat("Gender:")
unique(stroke_data$gender)
cat("Married:")
unique(stroke_data$ever_married)
cat("Work type:")
unique(stroke_data$work_type)
cat("Residence type:")
unique(stroke_data$Residence_type)
cat("Smoking:")
unique(stroke_data$smoking_status)
# how many "N/A" values are in my dataset per column?
miss_scan_count(data = stroke_data, search = list("N/A", "Unknown"))
fig(15, 8)
stroke_data %>%
group_by(smoking_status) %>%
summarise(count = length(smoking_status)) %>%
mutate(smoking_status = factor(smoking_status)) %>%
ggplot(aes(x = fct_reorder(smoking_status, count),
y = count,
fill = factor(ifelse(smoking_status=="Unknown","Unknown","Known")))) +
geom_col() +
geom_text(aes(label = count, x = smoking_status, y = count), size = 6, hjust = 1.5) +
coord_flip() +
scale_fill_manual(values = c("Unknown" = "red", "Known" = "darkgrey")) +
labs(x = "smoking status") +
theme(legend.position = "none") +
theme_bigfont
# replace the "N/A" in bmi
stroke_data_clean <- replace_with_na(data = stroke_data,
replace = list(bmi = c("N/A"),
smoking_status = c("Unknown"))) %>%
# change bmi to numeric
mutate(bmi = as.numeric(bmi))
# check
summary(stroke_data_clean)
unique(stroke_data_clean$smoking_status)
fig(15, 8)
# visualize the missing values
vis_miss(stroke_data_clean, cluster = TRUE) +
theme_bigfont
fig(20, 30)
# create vector of column names with
cols <- stroke_data_clean %>%
select(-id, -smoking_status) %>%
names()
vis_plots_list <- list()
for (i in 1:length(cols)) {
vis_plots_list[[i]] <- stroke_data_clean %>%
arrange_at(cols[i]) %>%
vis_miss() +
labs(title = paste0("Ordered by ", cols[i]))
}
n <- length(vis_plots_list)
nCol <- floor(sqrt(n))
do.call("grid.arrange", c(vis_plots_list, ncol=nCol))
fig(10, 8)
# check distribution of bmi
ggplot(stroke_data_clean, aes(x = bmi)) +
geom_histogram() +
labs(title = "Distribution of BMI") +
theme_bigfont
fig(10,8)
# impute median and bind shadow to evaluate imputation
stroke_data_imp <- bind_shadow(stroke_data_clean) %>%
impute_median_at(.vars = c("bmi")) %>%
add_label_shadow()
# Explore the median values in bmi in the imputed dataset
ggplot(stroke_data_imp,
aes(x = bmi_NA, y = bmi)) +
geom_boxplot() +
labs(title = "Comparison, no-missing vs. imputed values for BMI") +
theme_bigfont
stroke_data_imp <- impute_median_at(stroke_data_clean, .vars = c("bmi"))
fig(16,8)
p1 <- ggplot(stroke_data_imp,
aes(x = smoking_status, fill = smoking_status)) +
geom_bar() +
labs(title = "Before filling in NA values in smoking_status") +
theme(legend.position = "none") +
theme_bigfont
# fill imputation based on previous unique value in "smoking_status" column
after <- stroke_data_imp %>%
fill(smoking_status)
# Explore the median values in bmi in the imputed dataset
p2 <- ggplot(after,
aes(x = smoking_status, fill = smoking_status)) +
geom_bar() +
labs(title = "After filling in NA values in smoking_status") +
theme(legend.position = "none") +
theme_bigfont
p1 + p2
stroke_data_imp2 <- stroke_data_imp %>%
fill(smoking_status) %>%
#mutate(across(c(smoking_status)), replace(., is.na(.), "never smoked")) %>%
mutate(across(c(hypertension, heart_disease), factor),
across(where(is.character), as.factor),
across(where(is.factor), as.numeric),
stroke = factor(ifelse(stroke == 0, "no", "yes")))
stroke_data_imp2 <- stroke_data_imp2 %>%
mutate(bmi = case_when(bmi < 18.5 ~ "underweight",
bmi >= 18.5 & bmi < 25 ~ "normal weight",
bmi >= 25 & bmi < 30 ~ "overweight",
bmi >= 30 ~ "obese"),
bmi = factor(bmi, levels = c("underweight", "normal weight", "overweight", "obese"), order = TRUE))
fig(10, 8)
select(stroke) %>%
ggplot(aes(x = stroke)) +
geom_bar() +
theme_bigfont
# plot prop of people who had a stroke
stroke_data_imp2 %>%
select(stroke) %>%
ggplot(aes(x = stroke)) +
geom_bar() +
theme_bigfont
# count how many people had a stroke and the prop
stroke_data_imp2 %>%
group_by(stroke) %>%
summarize(n = n()) %>%
mutate(prop = round(n / sum(n), 2))
# check imbalance ratio
imbalanceRatio(as.data.frame(stroke_data_imp2), classAttr = "stroke")
stroke_test <- stroke_data_imp2 %>%
mutate(stroke = as.character(stroke),
across(where(is.factor), as.numeric),
stroke = factor(stroke))
stroke_oversampled <-
oversample(
as.data.frame(stroke_test),
classAttr = "stroke",
ratio = 1,
method = "MWMOTE"
)
head(stroke_oversampled)
stroke_oversampled %>%
group_by(stroke) %>%
summarize(n = n()) %>%
mutate(prop = round(n / sum(n), 2))
stroke_data_final <- stroke_oversampled %>% select(-id)
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
library(tidyverse)
library(rethinking)
library(brms)
library(tidybayes)
theme_set(theme_light())
gc()
library(tidyverse)
library(rethinking)
library(brms)
library(tidybayes)
theme_set(theme_light())
set.seed(2022)
n <- 100
temp <- rnorm(n)
shark <- rnorm(n, temp)
ice_cream <- rnorm(n, temp)
library(dagitty)
mad_dag <- dagitty("dag{M -> A -> D}")
impliedConditionalIndependencies(mad_dag)
smoke_dag <- dagitty("dag{X -> Y <- A -> S}")
impliedConditionalIndependencies(smoke_dag)
library(tidyverse)
library(rethinking)
library(brms)
library(tidybayes)
data(WaffleDivorce)
d <- list()
d$A <- standardize( WaffleDivorce$MedianAgeMarriage )
d$D <- standardize( WaffleDivorce$Divorce )
d$M <- standardize( WaffleDivorce$Marriage )
m5.3_A <- quap(
alist(
## A -> D <- M
D ~ dnorm( mu , sigma ) ,
mu <- a + bM*M + bA*A ,
a ~ dnorm( 0 , 0.2 ) ,
bM ~ dnorm( 0 , 0.5 ) ,
bA ~ dnorm( 0 , 0.5 ) ,
sigma ~ dexp( 1 ),
## A -> M
M ~ dnorm( mu_M , sigma_M ),
mu_M <- aM + bAM*A,
aM ~ dnorm( 0 , 0.2 ),
bAM ~ dnorm( 0 , 0.5 ),
sigma_M ~ dexp( 1 )
) , data = d )
e precis(5.3_A)
precis(5.3_A)
precis(m5.3_A)
A_seq <- seq( from=-2 , to=2 , length.out=30 )
# prep data
sim_dat <- data.frame( A=A_seq )
sim_dat
# simulate M and then D, using A_seq
s <- sim( m5.3_A , data=sim_dat , vars=c("M","D") )
s
plot( sim_dat$A , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated A" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$A )
mtext( "Total counterfactual effect of A on D" )
# new data frame, standardized to mean 26.1 and std dev 1.24
sim2_dat <- data.frame( A=(c(20,30)-26.1)/1.24 )
s2 <- sim( m5.3_A , data=sim2_dat , vars=c("M","D") )
mean( s2$D[,2] - s2$D[,1] )
library(rethinking)
data(WaffleDivorce)
d <- WaffleDivorce
d$D <- standardize( d$Divorce )
d$M <- standardize( d$Marriage )
d$A <- standardize( d$MedianAgeMarriage )
m5H2 <- quap(
alist(
# A -> D
D ~ dnorm( muD , sigmaD ),
muD <- aD + bAD*A,
# M -> A
A ~ dnorm( muA , sigmaA ),
muA <- aA + bMA*M,
# priors
c(aD,aA) ~ dnorm(0,0.2),
c(bAD,bMA) ~ dnorm(0,0.5),
c(sigmaD,sigmaA) ~ dexp(1)
) , data=d )
precis(m5H2)
d$D
d$Divorce
d$Marriage
precis(m5H2)
plot( sim_dat$M , colMeans(s$A) , ylim=c(-2,2) , type="l" ,
xlab="manipulated M" , ylab="counterfactual A" )
M_seq <- seq( from=-3 , to=3 , length.out=30 )
sim_dat <- data.frame( M=M_seq )
s <- sim( m5H2 , data=sim_dat , vars=c("A","D") )
plot( sim_dat$M , colMeans(s$A) , ylim=c(-2,2) , type="l" ,
xlab="manipulated M" , ylab="counterfactual A" )
shade( apply(s$A,2,PI) , sim_dat$M )
mtext( "Counterfactual M -> A" )
plot( sim_dat$M , colMeans(s$D) , ylim=c(-2,2) , type="l" ,
xlab="manipulated M" , ylab="counterfactual D" )
shade( apply(s$D,2,PI) , sim_dat$M )
mtext( "Counterfactual M -> A -> D" )
(10 - mean(d$Marriage))/sd(d$Marriage)
M_seq <- c( 0 , -2.67 )
M_seq
sim_dat <- data.frame( M=M_seq )
sim_dat
s <- sim( m5H2 , data=sim_dat , vars=c("A","D") )
s
diff <- s$D[,2] - s$D[,1]
diff
mean( diff )
dag_coords <-
tibble(name = c("S", "A", "M", "D"),
x = c(1, 1, 2, 3),
y = c(3, 1, 2, 1))
dag_coords
dagify(D ~ A + M,
M ~ A + S,
A ~ S,
coords = dag_coords)
library(ggdag)
install.packages('ggdag')
library(ggdag)
dagify(D ~ A + M,
M ~ A + S,
A ~ S,
coords = dag_coords)
dagify(D ~ A + M,
M ~ A + S,
A ~ S,
coords = dag_coords) %>%
ggplot(aes(x = x, y = y, xend = xend, yend = yend)) +
geom_dag_text(color = "black", size = 10) +
geom_dag_edges(edge_color = "black", edge_width = 2,
arrow_directed = grid::arrow(length = grid::unit(15, "pt"),
type = "closed")) +
theme_void()
div_dag <- dagitty("dag{S -> M -> D; S -> A -> D; A -> M}")
impliedConditionalIndependencies(div_dag)
data("WaffleDivorce")
WaffleDivorce
south_divorce <- WaffleDivorce %>%
as_tibble() %>%
select(D = Divorce,
A = MedianAgeMarriage,
M = Marriage,
S = South) %>%
drop_na(everything()) %>%
mutate(across(where(is.double), standardize))
b5h4 <- brm(D ~ A + M + S, data = south_divorce, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(exponential(1), class = sigma)),
iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
file = here("fits", "chp5", "b5h4"))
library(here)
b5h4 <- brm(D ~ A + M + S, data = south_divorce, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(exponential(1), class = sigma)),
iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
file = here("chp5", "b5h4"))
b5h4 <- brm(D ~ A + M + S, data = south_divorce, family = gaussian,
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 0.5), class = b),
prior(exponential(1), class = sigma)),
iter = 4000, warmup = 2000, chains = 4, cores = 4, seed = 1234,
file = here("fits", "chp5", "b5h4"))
spread_draws(b5h4, b_S) %>%
ggplot(aes(x = b_S)) +
stat_halfeye(.width = c(0.67, 0.89, 0.97)) +
labs(x = expression(beta[S]), y = "Density")
library(dagitty)
dag_6M1 <- dagitty("dag{
U [unobserved]
V [unobserevd]
X -> Y
X <- U -> B <- C -> Y
U <- A <- C
C <- V -> Y
}")
coordinates(dag_6M1) <- list(
x = c(X = 0, Y = 2, U = 0, A = 1, B = 1, C = 2, V = 2.5),
y = c(X = 2, Y = 2, U = 4, A = 5, B = 3, C = 4, V = 3)
)
drawdag(dag_6M1)
coordinates(dag_6M1) <- list(
x = c(X = 0, Y = 2, U = 0, A = 1, B = 1, C = 2, V = 2.5),
y = c(X = 2, Y = 2, U = 1, A = 0.5, B = 1.5, C = 1, V = 1.5)
)
drawdag(dag_6M1)
coordinates(dag_6M1) <- list(
x = c(X = 0, Y = 2, U = 0, A = 1, B = 1, C = 2, V = 2.5),
y = c(X = 2, Y = 2, U = 1, A = 0.5, B = 1.5, C = 1, V = 1.5)
)
dag_6M1 <- dagitty("dag{
U [unobserved]
V [unobserevd]
X -> Y
X <- U -> B <- C -> Y
U <- A -> C
C <- V -> Y
}")
coordinates(dag_6M1) <- list(
x = c(X = 0, Y = 2, U = 0, A = 1, B = 1, C = 2, V = 2.5),
y = c(X = 2, Y = 2, U = 1, A = 0.5, B = 1.5, C = 1, V = 1.5)
)
drawdag(dag_6M1)
adjustmentSets( dag_6M1 , exposure="X" , outcome="Y" )
dag_6M1 <- dagitty("dag{
U [unobserved]
V [unobserevd]
X -> Y
X <- U -> B <- C -> Y
U <- A -> C
C <- V -> Y
}")
coordinates(dag_6M1) <- list(
x = c(X = 0, Y = 2, U = 0, A = 1, B = 1, C = 2, V = 2.5),
y = c(X = 2, Y = 2, U = 1, A = 0.5, B = 1.5, C = 1, V = 1.5)
)
drawdag(dag_6M1)
adjustmentSets( dag_6M1 , exposure="X" , outcome="Y" )
