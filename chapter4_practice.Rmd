---
title: "Chapter 4 - Exercise"
author: "Hoang-Chau Luong"
date: '2022-08-18'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Medium

## **4M1**

For the model definition below, simulate observed y values from the prior (not the posterior).

$$
y_{i} \sim \text{Normal}(\mu, \sigma) \\
\mu \sim \text{Normal}(0, 10) \\
\sigma \sim \text{Exponential}(1)
$$

```{r}
library(tidyverse)
library(rethinking)
theme_set(theme_light())
sim <- tibble(
  mu = rnorm(n = 1e4, mean = 0, sd = 10),
  sigma = rexp(n = 1e4, rate = 1)
) %>% 
  mutate(y = rnorm(n = 10000, mean = mu, sd = sigma))

ggplot(sim, aes(x = y)) +
  geom_density() +
  labs(x = "y", y = "Density")
```


## **4M2**

Translate the model just above into a `quap` formula.

```{r}
flist <- alist(
  y ~ dnorm(mu, sigma),
  mu ~ dnorm(0, 10),
  sigma ~ dexp(1)
)
```

## **4M3**

Translate the `quap` model formula below into a mathematical model definition

$$
y_{i} \sim \text{Normal}(\mu, \sigma) \\
\mu = a + b\times x \\
a \sim \text{Normal(0, 10)} \\
b \sim \text{Uniform(0, 1)} \\
\sigma \sim \text{Exponential(1)}
$$

## **4M4**

A sample of students is measured for height each year for 3 years. After the third year, you want to fit a linear regression predicting height using year as a predictor. Write down the mathematical model definition for this regression, using any variable names and priors you choose. Be prepared to defend your choice of priors.

$$
h_{ij} \sim \text{Normal}(\mu_{ij}, \sigma) \\
\mu_{ij} = \alpha + \beta(y_{i} - \bar{y}) \\
\alpha \sim \text{Normal}(100, 10) \\
\beta \sim \text{Normal}(0, 10) \\
\sigma \sim \text{Exponential(1)}
$$

Because height is centered, `α` represents the average height in the average year (i.e., year 2). The prior of `Normal(100, 10)` was chosen assuming that height is measured in centimeters and that that sample is of children who are still growing.

The slope is extremely vague. The a prior centered on zero, and the standard deviation of the prior of 10 represents a wide range of possible growth (or shrinkage). During growth spurts, height growth averages 6–13 cm/year. The standard deviation of 10 encompasses the range we might expect to see if growth were occurring at a high rate.

Finally, the exponential prior on `σ` assumes an average deviation of 1.

Prior predictive simulations also appear to give reasonably plausible regression lines, given our current assumptions.

```{r}
n <- 50

tibble(
  group = seq_len(n),
  alpha = rnorm(n, 100, 10),
  beta  = rnorm(n, 0, 10),
  sigma = rexp(n, 1)
) %>% 
  expand(nesting(group, alpha, beta, sigma), year = 1:3) %>% 
  mutate(height = rnorm(n(), mean = alpha + beta * (year - mean(year)), sd = sigma)) %>% 
  ggplot(aes(x = year, y = height, group = group)) +
  geom_line(color = "blue", alpha = 0.6) +
  labs(x = "Year", y = "Height")
```

## **4M5**

Now suppose I remind you that every student got taller each year. Does this information lead you to change your choice of priors? How?

**Answer:**

Yes. Because we know that an increase in year will always lead to increased height, we know that `β` will be positive. Therefore, our prior should reflect this by using, for example, a log-normal distribution

$$
\beta \sim \text{Log-Normal(1, 0.5)}
$$

This prior gives an expectation of about `3cm` per year, with the `89%` highest density interval between 0.87cm and 5.18cm per year.

```{r}
library(tidybayes)

set.seed(123)
samples <- rlnorm(1e6, 1, 0.5)
bounds <- mean_hdi(samples, .width = 0.89)

ggplot() +
  stat_function(data = tibble(x = c(0, 10)), mapping = aes(x = x),
                geom = "line", fun = dlnorm,
                args = list(meanlog = 1, sdlog = 0.5)) +
  geom_ribbon(data = tibble(x = seq(bounds$ymin, bounds$ymax, 0.01)),
              aes(x = x, ymin = 0, ymax = dlnorm(x, 1, 0.5)),
              alpha = 0.8) +
  scale_x_continuous(breaks = seq(0, 10, 2)) +
  labs(x = expression(beta), y = "Density")
```

Prior predictive simulations of plausible lines using this new log-normal prior indicate that these priors still represent plausible values. Most the lines are positive, due to the prior constraint. However, because of variation around the mean, some lines do show a decrease in height. If it is truly impossible for students to shrink, then data like this might arise from measurement error.

```{r}
n <- 50

tibble(group = seq_len(n), 
       alpha = rnorm(n, 100, 10),
       beta = rlnorm(n, 1, 0.5),
       sigma = rexp(n, 1)) %>% 
  expand(nesting(group, alpha, beta, sigma), year = c(1, 2, 3)) %>% 
  mutate(height = rnorm(n(), alpha + beta * (year - mean(year)), sigma)) %>% 
  ggplot(aes(x = year, y = height, group = group)) +
  geom_line(color = "blue", alpha = 0.7) +
  labs(x = "Year", y = "Height") 
```

## **4M6**

Now suppose I tell you that the variance among heights for students of the same age is never more than 64cm. How does this lead you to revise your priors?

**Answer:**

A variance of 64cm corresponds to a standard deviation of 8cm. Our current prior of $σ ∼ Exponential(1)$ gives very little probability mass to values greater than 8. However, it is still theoretically possible. If we want to truly constrain the variance in this way, we could use a Uniform(0, 8) prior. This would eliminate all values that would result in a variance greater than 64cm. 

## **4M7**

Refit model `m4.3` from the chapter, but omit the mean weight xbar this time. Compare the new model’s posterior to that of the original model. In particular, look at the covariance among the parameters. What is different? Then compare the posterior predictions of both models.

**Answer:**

Once we take away the mean weight, the intercept $α$ will no longer be the mean height. Instead it will be the mean height when weight is zero (which never happens). Let’s see what happens, if we use the original priors:

First, we’ll reproduce m4.3 using `quap()`, and then again using `brm()`. The covariance matrix from both is the same, as we would expect.

```{r}
library(rethinking)
library(brms)

data(Howell1)

how_dat <- Howell1 %>%
  filter(age >= 18) %>%
  mutate(weight_c = weight - mean(weight))

# first, duplicate model with `quap`
m4.3 <- quap(alist(height ~ dnorm(mu, sigma),
                   mu <- a + b * (weight_c),
                   a ~ dnorm(178, 20),
                   b ~ dlnorm(0, 1),
                   sigma ~ dunif(0, 50)),
             data = how_dat)

m4.3b <- quap(alist(height ~ dnorm(mu, sigma),
                    mu <- a + b * weight,
                    a ~ dnorm(178, 20),
                    b ~ dnorm(0, 1),
                    sigma ~ dunif(0, 50)),
              data = how_dat)
```

```{r}
precis(m4.3, digits = 3)
#         mean   sd   5.5%  94.5%
# a     154.60 0.27 154.17 155.03
# b       0.90 0.04   0.84   0.97
# sigma   5.07 0.19   4.77   5.38

precis(m4.3b, digits = 3)
#         mean   sd   5.5%  94.5%
# a     114.53 1.90 111.50 117.56
# b       0.89 0.04   0.82   0.96
# sigma   5.07 0.19   4.77   5.38
```

So the slope is the same, but the intercept has changed, even `mean` and `sd`(I guess this difference coming from the addition of distribution $\text{a - mean(weigth)*b}$). 

I'm using mathematics formula to justify this comment.

$$
\text{We assume indepence between Weight and Height, from this assumption we have} \\
\text{f}_{x}(x) = \frac{1}{\sigma_{x}\sqrt{2\pi}}\text{exp}(-\frac{(x-\mu_{x})^2}{2\sigma^{2}_{x}}), \ \text{f}_{y}(y) = \frac{1}{\sigma_{y}\sqrt{2\pi}}\text{exp}(-\frac{(y-\mu_{y})^2}{2\sigma^{2}_{y}}) \\
\text{From that, with vector V = (X, Y), we have joint distribution with v = (x, y)}\in R^{2} \\
\text{f}_{v}(v) = f_{x}(x)f_{y}(y) = \frac{1}{2\pi\sigma_{x}\sigma_{y}}\text{exp}[\frac{-1}{2}(\frac{(x-\mu_{x})^2}{\sigma_{x}^{2}} + \frac{(y-\mu_{y})^2}{\sigma_{y}^{2}})] \\ 
= \frac{1}{\sqrt{(2\pi^2)}|\sum|}\text{exp}[\frac{-1}{2}(v-\mu)^{'}\sum^{-1}(v-\mu)] \\
\text{in that}\  \mu = (\frac{\mu_{x}}{\mu_{y}}) \in R^{2}, \sum = (\begin{bmatrix}
\sigma_{x}^{2} & 0  \\
0 & \sigma_{y}^{2}  \\
\end{bmatrix}) \in R^{2\times2}. \text{Due to} \sum = \sigma_{x}^{2}\sigma_{y}^{2},\ \text{inverse}(\sum) = (\begin{bmatrix}
\sigma_{x}^{-2} & 0  \\
0 & \sigma_{y}^{-2}  \\
\end{bmatrix}), \ \text{that} \\
(v-\mu)^{'}\sum^{-1}(v-\mu) = (x-\mu_{x} \ \ y-\mu_{y})(\begin{bmatrix}
\sigma_{x}^{-2} & 0  \\
0 & \sigma_{y}^{-2}  \\
\end{bmatrix})(\begin{bmatrix}
x-\mu_{x}  \\
y-\mu_{y}  \\
\end{bmatrix}) = \frac{(x-\mu_{x})^2}{\sigma_{x}^{2}} + \frac{(y-\mu_{y})^2}{\sigma_{y}^{2}}. \\
\text{V} \sim \text{Normal}(\mu = \begin{bmatrix}
\mu_{x}  \\
\mu_{y}  \\
\end{bmatrix}, \ \sum = (\begin{bmatrix}
\sigma_{x}^{2} & 0  \\
0 & \sigma_{y}^{2}  \\
\end{bmatrix})) \\
Then, \\
A = X - 45Y = (1 \ \ \text{-45})(\begin{bmatrix}X \\ Y \end{bmatrix}) = (1 \ \ \text{-45})V \\
\mu_{a} = d + A\mu = 0 + (1 \ \ \text{-45})(\begin{bmatrix}\mu_{X} \\ \mu_{Y} \end{bmatrix}) = \mu_{X} - 45\mu_{Y} \\ 
\text{and} \\
\sigma_{a}^{2} = A\sum A^{T} = \sigma_{x}^{2} + 45^{2}\sigma_{y}^{2}
$$

We should expect this. You might want to confirm that the posterior predictions make sense, that the model fit correctly. When you do, you’ll see that this model makes the same predictions as the original one.

```{r}
round(vcov(m4.3), 3)

#           a     b sigma
# a     0.073 0.000 0.000
# b     0.000 0.002 0.000
# sigma 0.000 0.000 0.037

m4.3b <- quap(alist(height ~ dnorm(mu, sigma),
                    mu <- a + b * weight,
                    a ~ dnorm(178, 20),
                    b ~ dnorm(0, 1),
                    sigma ~ dunif(0, 50)),
              data = how_dat)

round(vcov(m4.3b), 3)
#            a      b sigma
# a      3.596 -0.078 0.009
# b     -0.078  0.002 0.000
# sigma  0.009  0.000 0.037
```

If you look at the same output for `m4.3`, you’ll see that there is no covariance like there is above between a and b. That −0.078 covariance seems pretty small. But remember that this is on the scale of the variables. Let’s convert to a correlation matrix instead:

```{r}
round( cov2cor(vcov( m4.3b )) , 2 )
# a      1.00 -0.99  0.03
# b     -0.99  1.00 -0.03
# sigma  0.03 -0.03  1.00
```

We have the conclusion that while these models make the same posterior predictions, but the parameters have quite different meanings and relationships with one another. There is nothing wrong with this new version of the model. But usually it is much easier to set priors, when we center the predictor variables. But you can always use prior simulations to set sensible priors, when in doubt.


Using `brm()`

```{r}
b4.3 <- brm(height ~ 1 + weight_c, data = how_dat, family = gaussian,
            prior = c(prior(normal(178, 20), class = Intercept),
                      prior(lognormal(0, 1), class = b, lb = 0),
                      prior(uniform(0, 50), class = sigma)),
            iter = 28000, warmup = 27000, chains = 4, cores = 4, seed = 1234,
            file = here("fits", "chp4", "b4.3-0"))

as_draws_df(b4.3) %>%
  as_tibble() %>% 
  select(b_Intercept, b_weight_c, sigma) %>%
  cov() %>%
  round(digits = 3)
#>             b_Intercept b_weight_c sigma
#> b_Intercept       0.074      0.000 0.000
#> b_weight_c        0.000      0.002 0.000
#> sigma             0.000      0.000 0.038
```

Now, let’s using the non-centered parameterization (original model). This time, we’ll use `brm()` and `quap()`.

```{r}
b4.3_nc <- brm(height ~ 1 + weight, data = how_dat, family = gaussian,
               prior = c(prior(normal(178, 20), class = Intercept),
                         prior(lognormal(0, 1), class = b, lb = 0),
                         prior(uniform(0, 50), class = sigma)),
               iter = 28000, warmup = 27000, chains = 4, cores = 4, seed = 1234,
               file = here("fits", "chp4", "b4.3_nc"))

as_draws_df(b4.3_nc) %>%
  as_tibble() %>% 
  select(b_Intercept, b_weight, sigma) %>%
  cov() %>%
  round(digits = 3)
#>             b_Intercept b_weight sigma
#> b_Intercept       3.653   -0.079 0.010
#> b_weight         -0.079    0.002 0.000
#> sigma             0.010    0.000 0.035
```

We now see non-zero covariances between the parameters. Lets compare the posterior predictions. We’ll generate hypothetical outcome plots which are animated to show the uncertainty in estimates Here we’ll just animate the estimated regression line using {gganimate} (Pedersen & Robinson, 2020). We can see that the predictions from the two models are nearly identical.

```{r}
library(gganimate)

weight_seq <- tibble(weight = seq(25, 70, length.out = 100)) %>%
  mutate(weight_c = weight - mean(how_dat$weight))

predictions <- bind_rows(
  predict(b4.3, newdata = weight_seq) %>%
    as_tibble() %>%
    bind_cols(weight_seq) %>%
    mutate(type = "Centered"),
  predict(b4.3_nc, newdata = weight_seq) %>%
    as_tibble() %>%
    bind_cols(weight_seq) %>%
    mutate(type = "Non-centered")
)

fits <- bind_rows(
  weight_seq %>%
    add_epred_draws(b4.3) %>%
    mutate(type = "Centered"),
  weight_seq %>%
    add_epred_draws(b4.3_nc) %>%
    mutate(type = "Non-centered")
) %>%
  ungroup()

bands <- fits %>%
  group_by(type, weight) %>%
  median_qi(.epred, .width = c(.67, .89, .97))

lines <- fits %>%
  filter(.draw %in% sample(unique(.data$.draw), size = 50))

ggplot(lines, aes(x = weight)) +
  facet_wrap(~type, nrow = 1) +
  geom_ribbon(data = predictions, aes(ymin = Q2.5, ymax = Q97.5), alpha = 0.3) +
  geom_lineribbon(data = bands, aes(y = .epred, ymin = .lower, ymax = .upper),
                  color = NA) +
  scale_fill_brewer(palette = "Blues", breaks = c(.67, .89, .97)) +
  geom_line(aes(y = .epred, group = .draw)) +
  geom_point(data = how_dat, aes(y = height), shape = 1, alpha = 0.7) +
  labs(x = "Weight", y = "Height", fill = "Interval") +
  transition_states(.draw, 0, 1)
```

## **4M8**

In the chapter, we used 15 knots with the cherry blossom spline. Increase the number of knots and observe what happens to the resulting spline. Then adjust also the width of the prior on the weights—change the standard deviation of the prior and watch what happens. What do you think the combination of know number and the prior on the weights controls?

**Answer:**

First lets duplicate the 15-knot spline model from the chapter. Then we’ll double the number of knots and play with the prior.

```{r}
library(splines)

data(cherry_blossoms)
cb_dat <- cherry_blossoms %>%
  drop_na(doy)

# original m4.7 model
knots_15 <- quantile(cb_dat$year, probs = seq(0, 1, length.out = 15))
B_15 <- bs(cb_dat$year, knots = knots_15[-c(1, 15)],
           degree = 3, intercept = TRUE)

cb_dat_15 <- cb_dat %>% 
  mutate(B = B_15)

b4.7 <- brm(doy ~ 1 + B, data = cb_dat_15, family = gaussian,
            prior = c(prior(normal(100, 10), class = Intercept),
                      prior(normal(0, 10), class = b),
                      prior(exponential(1), class = sigma)),
            iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,
            file = here("fits", "chp4", "b4.7"))
```

```{r}
original_draws <- cb_dat_15 %>% 
  add_epred_draws(b4.7) %>% 
  summarize(mean_hdi(.epred, .width = 0.89),
            .groups = "drop")

ggplot(original_draws, aes(x = year, y = doy)) +
  geom_vline(xintercept = knots_15, alpha = 0.5) +
  geom_hline(yintercept = fixef(b4.7)[1, 1], linetype = "dashed") +
  geom_point(alpha = 0.5) +
  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "#009FB7", alpha = 0.8) +
  labs(x = "Year", y = "Day in Year")
```


```{r}
# double the number of knots
knots_30 <- quantile(cb_dat$year, probs = seq(0, 1, length.out = 30))
B_30 <- bs(cb_dat$year, knots = knots_30[-c(1, 30)],
           degree = 3, intercept = TRUE)

cb_dat_30 <- cb_dat %>% 
  mutate(B = B_30)

b4.7_30 <- brm(doy ~ 1 + B, data = cb_dat_30, family = gaussian,
               prior = c(prior(normal(100, 10), class = Intercept),
                         prior(normal(0, 10), class = b),
                         prior(exponential(1), class = sigma)),
               iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,
               file = here("fits", "chp4", "b4.7_30"))

# and modify the prior
b4.7_30p <- brm(doy ~ 1 + B, data = cb_dat_30, family = gaussian,
                prior = c(prior(normal(100, 10), class = Intercept),
                          prior(normal(0, 2), class = b),
                          prior(exponential(1), class = sigma)),
                iter = 2000, warmup = 1000, chains = 4, cores = 4, seed = 1234,
                file = here("fits", "chp4", "b4.7_30p"))

# create plot data
spline_15 <- original_draws %>%
  select(-B) %>% 
  mutate(knots = "15 knots (original model)")

spline_30 <- cb_dat_30 %>% 
  add_epred_draws(b4.7_30) %>% 
  summarize(mean_hdi(.epred, .width = 0.89),
            .groups = "drop") %>% 
  select(-B) %>% 
  mutate(knots = "30 knots")

spline_30p <- cb_dat_30 %>% 
  add_epred_draws(b4.7_30p) %>% 
  summarize(mean_hdi(.epred, .width = 0.89),
            .groups = "drop") %>% 
  select(-B) %>% 
  mutate(knots = "30 knots; Tight prior")

all_splines <- bind_rows(spline_15, spline_30, spline_30p)

# make plot
ggplot(all_splines, aes(x = year, y = doy)) +
  geom_point(alpha = 0.5) +
  geom_ribbon(aes(ymin = ymin, ymax = ymax), fill = "#009FB7", alpha = 0.8) +
  facet_wrap(~knots, ncol = 1) +
  labs(x = "Year", y = "Day in Year")
```

# **Hard**

## **4H1**

First, fit the model with `quap`, to provide a quadratic approximation of the posterior. This is just as in the chapter.

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
d2 <- d[d$age>=18,]
xbar <- mean( d2$weight )

m <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- a + b*( weight - xbar ) ,
        a ~ dnorm( 178 , 20 ) ,
        b ~ dlnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d2 )

tibble(individual = 1:5,
       weight = c(46.95, 43.72, 64.78, 32.59, 54.63)) %>%
  mutate(weight_c = weight - mean(how_dat$weight)) %>%
  add_predicted_draws(b4.3) %>%
  group_by(individual, weight) %>%
  mean_qi(.prediction, .width = 0.89) %>%
  mutate(range = glue("[{sprintf('%0.1f', .lower)}--",
                      "{sprintf('%0.1f', .upper)}]"),
         .prediction = sprintf("%0.1f", .prediction)) %>%
  select(individual, weight, exp = .prediction, range) %>%
  kbl(align = "c", booktabs = TRUE,
      col.names = c("Individual", "weight", "expected height", "89% interval"))
```

Then produce samples from the quadratic approximate posterior. You could use `mvrnorm` directly, or the convenient `extract.samples` function:

```{r}
post <- extract.samples(m)
str(post)
```

Now we want to plug the weights in the table into this model, and then average over the posterior to compute predictions for each individual’s height. The question is ambiguous as to whether it wants µ only or rather the distribution of individual height measurements (using σ). I’ll show the harder approach, that uses σ and simulates individual heights. Also, I won’t use link or sim, but it’s fine if you did.

```{r}
y <- rnorm( 1e5 , post$a + post$b*( 46.95 - xbar ) , post$sigma )
mean(y)
PI(y,prob=0.89)
```

```{r}
f <- function( weight ) {
    y <- rnorm( 1e5 , post$a + post$b*( weight - xbar ) , post$sigma )
    return( c( mean(y) , PI(y,prob=0.89) ) )
}
weight_list <- c(46.95,43.72,64.78,32.59,54.63)
result <- sapply( weight_list , f )

rtab <- cbind( weight_list , t( result ) )
colnames(rtab) <- c("weight","height","5%","94%")
rtab
```

## **4H2**

Select out all the rows in the Howell1 data with ages below 18 years of age. If you do it right, you should end up with a new data frame with 192 rows in it

### **(a)**

Fit a linear regression to these data, using quap. Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets?

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
d3 <- d[ d$age < 18 , ]
str(d3)
```

```{r}
xbar <- mean( d3$weight )
m <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- a + b*( weight - xbar ) ,
        a ~ dnorm( 178 , 20 ),
        b ~ dnorm( 0 , 10 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d3 )
precis(m)

#         mean   sd   5.5%  94.5%
# a     108.38 0.61 107.41 109.36
# b       2.72 0.07   2.61   2.83
# sigma   8.44 0.43   7.75   9.13
```

The estimates suggest that the `MAP` coefficient for weight is 2.7. This implies that for a unit change of 1kg of weight, we predict an average of 2.7cm of increase in height.

### **(b)**

Now to plot the raw data and superimpose the model estimates, modify the code in Chapter 4. We will sample from the naive posterior, then compute 89% intervals for the mean and predicted heights. This is what the complete code looks like, if you opt not to use the convenience functions `link` and `sim`:

```{r}
post <- extract.samples( m )
w.seq <- seq(from=1,to=45,length.out=50)
mu <- sapply( w.seq , function(z) mean( post$a + post$b*(z-xbar) ) )
mu.ci <- sapply( w.seq , function(z)
  PI( post$a + post$b*(z-xbar) , prob=0.89 ) )
pred.ci <- sapply( w.seq , function(z)
  PI( rnorm( 10000 , post$a + post$b*(z-xbar) , post$sigma) , 0.89 ) )
```

```{r}
plot( height ~ weight , data=d3 ,
  col=col.alpha("slateblue",0.5) , cex=0.5 )
lines( w.seq , mu )
lines( w.seq , mu.ci[1,] , lty=2 )
lines( w.seq , mu.ci[2,] , lty=2 )
lines( w.seq , pred.ci[1,] , lty=2 )
lines( w.seq , pred.ci[2,] , lty=2 )
```

### **(c)**

What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don’t have to write any new code. Just explain what the model appears to be doing a bad job of, and what you hypothesize would be a better model.

The major problem with this model appears to be that the relationship between weight and height, for non-adults, isn’t very linear. Instead it is curved. As a result, at low weight values, the predicted mean is above most of the actual heights. At middle weight values, the predicted mean is below most of the heights. Then again at high weight values, the mean is above the heights

A parabolic model would likely fit these data much better. But that’s not the only option. What we’re after essentially is some way to model a reduction of the slope between height and weight, as weight increases. And onwards to the next solution, which does that, for the entire data.

## **4H3**

Suppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body weight that scales with height!” Let’s take your colleague’s advice and see what happens.

### **(a)**

Model the relationship between height (cm) and the natural logarithm of weight (log-kg). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Can you interpret the resulting estimates?

```{r}
library(rethinking)
data(Howell1)
d <- Howell1
logxbar <- mean( log(d$weight) )
mlw <- quap(
    alist(
        height ~ dnorm( mean=mu , sd=sigma ) ,
        mu <- a + b*( log(weight) - logxbar ) ,
        a ~ dnorm( 178 , 20 ) ,
        b ~ dnorm( 0 , 10 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d )
precis(mlw)
#         mean   sd   5.5%  94.5%
# a     138.27 0.22 137.92 138.62
# b      47.02 0.38  46.41  47.63
# sigma   5.14 0.16   4.89   5.38
```

Pretty hard to know what to make of these estimates, aside from the fact that the confidence intervals are quite narrow, owing to there being 544 rows. The estimate for b (β) is hard to understand, because it refers to log-kg, not raw kg. It means that for every increase of 1 log-kg of weight, you expect a increase of 47 cm of height. But what’s a log-kg? You want to know what the model predicts on the natural scale of measurement. So now to plotting...

### **(b)**

Begin with this plot: `plot( height ~ weight , data=Howell1 )`. Then use samples
from the quadratic approximate posterior of the model in (a) to superimpose on the plot: (1) the predicted mean height as a function of weight, (2) the 97% interval for the mean, and (3) the 97% interval for predicted heights.

**Answer**

Begin by sampling from the naive posterior and computing the confidence intervals as per the examples in the book. Again, I’ll not use the convenience functions, but it’s fine if you did.

```{r}
post <- extract.samples(mlw)
w.seq <- seq(from=4,to=63,length.out=50)
mu <- sapply( w.seq , function(z) mean( post$a+post$b*(log(z)-logxbar) ) )
mu.ci <- sapply( w.seq , function(z) PI( post$a+post$b*(log(z)-logxbar) ) )
h.ci <- sapply( w.seq , function(z)
  PI( rnorm(10000,post$a+post$b*(log(z)-logxbar),post$sigma) ) )
```

```{r}
plot( height ~ weight , data=d , col=col.alpha("slateblue",0.4) )
lines( w.seq , mu )
lines( w.seq , mu.ci[1,] , lty=2 )
lines( w.seq , mu.ci[2,] , lty=2 )
lines( w.seq , h.ci[1,] , lty=2 )
lines( w.seq , h.ci[2,] , lty=2 )
```

The model may have been linear, but plotted on the raw scale of measurement, it is clearly non-linear. Not only is the trend for the mean curved, but the variance around the mean is not constant, on this scale. Instead, the variance around the mean increases with weight. On the scale you fit the model on, the variance was assumed to be constant. But once you transform the measurement scale, it usually won’t be.

Notice also that the estimate for the mean is so precise that you can hardly even see the confidence interval for it. Don’t get too confident about such results, though. Remember, all inferences of the model are conditional on the model. Even estimated trends that do a terrible job of prediction can have tight confidence intervals, when the data set is large.

## **4H4**

Plot the prior predictive distribution for the parabolic polynomial regression model in the chapter. You can modify the code that plots the linear regression prior predictive distribution. Can you modify the prior distributions of $α, \ β_{1}, \text{and }β_{2}$ so that the prior predictions stay within the biologically reasonable outcome space? That is to say: Do not try to fit the data by hand. But do try to keep the curves consistent with what you know about height and weight, before seeing these exact data.

```{r}
library(rethinking)
data(Howell1)
d <- Howell1

d$weight_s <- ( d$weight - mean(d$weight) )/sd(d$weight)
d$weight_s2 <- d$weight_s^2

m4.5 <- quap(
    alist(
        height ~ dnorm( mu , sigma ) ,
        mu <- a + b1*weight_s + b2*weight_s2 ,
        a ~ dnorm( 178 , 20 ) ,
        b1 ~ dlnorm( 0 , 1 ) ,
        b2 ~ dnorm( 0 , 1 ) ,
        sigma ~ dunif( 0 , 50 )
    ) , data=d )
```

```{r}
set.seed(45)
prior <- extract.prior( m4.5 )
precis( prior )
```

We want to simulate curves (parabolas) from this prior. One way is to use `link`. Then we won’t have to write the linear model again.

```{r}
w_seq <- seq(from = min(d$weight_s), to = max(d$weight_s), length.out = 50)
w2_seq <- w_seq^2
mu <- link(m4.5, post = prior, data = list(weight_s = w_seq, weight_s2 = w2_seq))
```

Now mu should contain 1000 parabolas. We’ll plot just the first 50.

```{r}
plot(NULL, xlim = range(w_seq), ylim = c(55, 270),
     xlab = "weight (std)", ylab = "height")
for(i in 1:50) lines(w_seq, mu[i, ], col = col.alpha("black", 0.5))
```

Recall that the world’s tallest person was 270cm tall. The tallest person in the sample is about 180cm. The prior curvature is not very strong. Those parabolas hardly bend at all. We can increase the standard deviation on the b2 prior, but that will produce some silly shapes (left below), where either
average weight is tallest or shortest. That can’t be right. The basic problem is that b2 needs to be negative to make the curve bend down, but b1 has to also change in order to move the maximum height to the right. It’s all a bit confusing, and is they key reason that working with polynomial models is so hard. The prior on the right below can only bend down, but I’ve made the linear model $a + b1*weight\_s - b2*weight\_s2$ and given b2 a log-Normal prior.

A key problem in getting reasonable curves here is that obviously a and b1 and b2 are correlated in the family of reasonable curves. But the priors are uncorrelated—they are independent of one another. Still, if you can get independent priors to at least live within some reasonably space of outcome values, that’s a lot better than flat priors. What would flat priors look like here? Something like this:

These prior curves actually strongly favor explosive growth or shrinkage near the mean. This is a general phenomenon with “flat” priors: Once the predictor is at all complicated, “flat” does not imply “no relationship.”

Do any of the priors above make a difference for inference in this sample? No. There is a lot of data and the model is quite simple, in terms of the way that parameters relate to predictions. This will not always be the case.

## **4H5**

Return to `data(cherry_blossoms)` and model the association between blossom `date(doy)` and March temperature `(temp)`. Note that there are many missing values in both variables. You may consider a linear model, a polynomial, or a spline on temperature. How well does temperature trend predict the blossom trend?

```{r}
library(rethinking)
data(cherry_blossoms)
colSums( is.na(cherry_blossoms) )

d <- cherry_blossoms
d2 <- d[ complete.cases( d$doy , d$temp ) , c("doy","temp") ]
```


You should be left with 787 rows. If you just `plot(d2)` you’ll see there is surely some relationship. But it’s pretty noisy. I’m going to go ahead and build a spline here, for the sake of the example. But a linear fit wouldn’t be awful, even though at the extremes this relationship cannot possibly be linear. 

First build the knot list. We’ll build the knots on the temperature record, thinking of doy as the outcome variable

```{r}
num_knots <- 30
knot_list <- quantile( d2$temp , probs=seq(0,1,length.out=num_knots) )
library(splines)
B <- bs(d2$temp,
    knots=knot_list[-c(1,num_knots)] ,
    degree=3 , intercept=TRUE )
```

```{r}
m4H5 <- quap(
    alist(
        D ~ dnorm( mu , sigma ) ,
        mu <- a + B %*% w ,
        a ~ dnorm(100,10),
        w ~ dnorm(0,10),
        sigma ~ dexp(1)
    ), data=list( D=d2$doy , B=B ) ,
    start=list( w=rep( 0 , ncol(B) ) ) )
```

```{r}
mu <- link( m4H5 )
mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI, 0.97 )
plot( d2$temp , d2$doy , col=col.alpha(rangi2,0.3) , pch=16 , xlab="temp" , ylab="doy" )
o <- order( d2$temp )
lines( d2$temp[o] , mu_mean[o] , lwd=3 )
shade( mu_PI[,o] , d2$temp[o] , col=grau(0.3) )
```

There is a silly amount of wiggle in this spline. I used 30 knots and quite loose prior weights, so this wiggle isn’t unexpected. It also probably isn’t telling us anything causal. Overall the trend is quite linear, aside from the odd drop just before 6 degrees. This could be real, or it could be an artifact of changes in the record keeping. The colder dates are also older and the temperatures for older dates were estimated differently

## **4H6**

Simulate the prior predictive distribution for the cherry blossom spline in the chapter. Adjust the prior on the weights and observe what happens. What do you think the prior on the weights is doing?

```{r}
library(rethinking)
data(cherry_blossoms)
d <- cherry_blossoms
d2 <- d[ complete.cases(d$doy) , ] # complete cases on doy
num_knots <- 15
knot_list <- quantile( d2$year , probs=seq(0,1,length.out=num_knots) )
library(splines)
B <- bs(d2$year,
    knots=knot_list[-c(1,num_knots)] ,
    degree=3 , intercept=TRUE )
m4.7 <- quap(
    alist(
        D ~ dnorm( mu , sigma ) ,
        mu <- a + B %*% w ,
        a ~ dnorm(100,10),
        w ~ dnorm(0,10),
        sigma ~ dexp(1)
    ), data=list( D=d2$doy , B=B ) ,
    start=list( w=rep( 0 , ncol(B) ) ) )
```

Now let’s extract the prior and use it to simulate observations:

```{r}
p <- extract.prior( m4.7 )
mu <- link( m4.7 , post=p )
mu_mean <- apply( mu , 2 , mean )
mu_PI <- apply( mu , 2 , PI, 0.97 )
plot( d2$year , d2$doy , col=col.alpha(rangi2,0.3) , pch=16 , 
      xlab="year" , ylab="doy" , ylim=c(60,140) )
lines( d2$year , mu_mean , lwd=3 )
shade( mu_PI , d2$year , col=grau(0.3) )
```

These priors imply no specific trend and very wide range of possibilities inside the gray region, including unrealistically early blossom dates in the low range and unrealistically late dates in the high range.

This is more satisfying if instead of a compatibility region we plot individual splines sampled from the prior. Here are 20 splines sampled from the prior:

```{r}
p <- extract.prior( m4.7 )
mu <- link( m4.7 , post=p )
plot( d2$year , d2$doy , col=col.alpha(rangi2,0.3) , pch=16 , 
      xlab="year" , ylab="day in year" , ylim=c(60,140) )
for ( i in 1:20 ) lines( d2$year , mu[i,] , lwd=1 )
```

What happens when we tighten the priors?

```{r}
m4.7b <- quap(
    alist(
        D ~ dnorm( mu , sigma ) ,
        mu <- a + B %*% w ,
        a ~ dnorm(100,10),
        w ~ dnorm(0,1),
        sigma ~ dexp(1)
    ), data=list( D=d2$doy , B=B ) ,
    start=list( w=rep( 0 , ncol(B) ) ) )
p <- extract.prior( m4.7b )
mu <- link( m4.7b , post=p )
plot( d2$year , d2$doy , col=col.alpha(rangi2,0.3) , pch=16 , 
      xlab="year" , ylab="day in year" , ylim=c(60,140) )
for ( i in 1:20 ) lines( d2$year , mu[i,] , lwd=1 )
```

Perhaps obvious in hindsight, the gray region gets tighter.

  The prior weights control how flexible the spline is in changing the local expectation. If you make the prior flat, then the spline is free to wiggle. The tighter the prior, the more evidence is needed to induce local wiggle.

## **4H8**

The cherry blossom spline in the chapter used an intercept α, but technically it doesn’t require one. The first basis functions could substitute for the intercept. Try refitting the cherry blossom spline without the intercept. What else about the model do you need to change to make this work?

**Answer:**

It is easy enough to just remove the intercept a from the model. But if that’s all we do, the prior won’t be anywhere near the data, since the prior weights are offsets from the intercept. So we need to either center the weights someplace else or just put a fixed intercept in the linear model. I’ll do the first:

```{r}
library(rethinking)
data("cherry_blossoms")
d <- cherry_blossoms
d2 <- d[complete.cases(d$doy), ] # complete cases on doy
num_knots <- 15
knot_list <- quantile(d2$year, probs = seq(0, 1, length.out = num_knots))
library(splines)
B <- bs(d2$year,
        knots = knot_list[-c(1, num_knots)],
        degree = 3, intercept = TRUE)

m4H7 <- quap(
  alist(
    D ~ dnorm(mu, sigma),
    mu <- 0 + B %*% w,
    w ~ dnorm(100, 10),
    sigma ~ dexp(1)
  ), data = list(D = d2$doy, B = B),
  start = list(w = rep(0, ncol(B)))
)
```

Note the 100 inside the prior weights. If you plot the posterior predictions, you’ll see they are essentially the same as before. If you don’t include the 100, you’ll see that the ends of the spline drift downwards, towards the prior. But there is so much data here that the core of the spline should look very similar. the prior predictions however would be absolutely bonkers.































